{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4dbe1a33a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pytorch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def create_meta_csv(dataset_path, destination_path):\n",
    "    # Change dataset path accordingly\n",
    "    DATASET_PATH = os.path.abspath(dataset_path)\n",
    "    csv_path=os.path.join(destination_path, 'dataset_attr.csv')\n",
    "    flist = []\n",
    "    emotions=[\"anger\",\"disgust\",\"fear\",\"happy\",\"neutral\", \"sad\", \"surprise\"]\n",
    "    for root, dirs, files in os.walk(DATASET_PATH, topdown=False):\n",
    "        for name in files:\n",
    "            if (name.endswith('.wav')): \n",
    "                fullName = os.path.join(root, name)\n",
    "                flist.append(fullName)\n",
    "\n",
    "    split_format = str('/') if sys.platform=='linux' else str('\\\\')\n",
    "    \n",
    "    filenames=[]\n",
    "    for idx,file in enumerate(flist):\n",
    "        filenames.append(file.split(split_format)) \n",
    "        # print(filenames[idx])\n",
    "    types=[]\n",
    "    for idx,path in enumerate(filenames):\n",
    "        types.append((flist[idx],emotions.index(path[-2]))) ##second last location has emotion name\n",
    "\n",
    "    with open(csv_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([(\"path\",\"label\")])\n",
    "        writer.writerows(types)\n",
    "    f.close()\n",
    "    # change destination_path to DATASET_PATH if destination_path is None \n",
    "    if destination_path == None:\n",
    "        destination_path = DATASET_PATH\n",
    "        # write out as dataset_attr.csv in destination_path directory\n",
    "        # if no error\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_load_meta_csv_df(dataset_path, destination_path, randomize=True, split=None):\n",
    "    if create_meta_csv(dataset_path, destination_path=destination_path):\n",
    "        dframe = pd.read_csv(os.path.join(destination_path, 'dataset_attr.csv'))\n",
    "\n",
    "    # shuffle if randomize is True or if split specified and randomize is not specified \n",
    "    # so default behavior is split\n",
    "    if randomize == True or (split != None and randomize == None):\n",
    "        # shuffle the dataframe here\n",
    "        dframe=dframe.sample(frac=1).reset_index(drop=True)\n",
    "        pass\n",
    "\n",
    "    if split != None:\n",
    "        train_set, test_set = train_test_split(dframe, split)\n",
    "        return dframe, train_set, test_set \n",
    "    \n",
    "    return dframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dframe, split_ratio):\n",
    "    # divide into train and test dataframes\n",
    "    train_data= dframe.iloc[:int((split_ratio) * len(dframe)), :]\n",
    "    test_data= dframe.iloc[int((split_ratio) * len(dframe)):,:]\n",
    "    test_data=test_data.reset_index(drop=True) #reset index for test data\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # test config\n",
    "    dataset_path =  os.path.dirname(os.getcwd())+'/Dataset'\n",
    "    print(\"dataset_path : \", dataset_path)\n",
    "    destination_path = os.getcwd()\n",
    "    classes = 7\n",
    "    total_rows = 2556\n",
    "    randomize = True\n",
    "    clear = True\n",
    "\n",
    "    # test_create_meta_csv()\n",
    "    df, trn_df, tst_df = create_and_load_meta_csv_df(dataset_path, destination_path=destination_path, randomize=randomize, split=0.99)\n",
    "    print(df.describe())\n",
    "    print(trn_df.describe())\n",
    "    print(tst_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
